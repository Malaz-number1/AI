{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edc382b-a44d-4ed3-b153-41d9de33d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5375ac-95b1-4dd9-94b8-e6ccf02b18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training_data.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0819e1ac-d98b-422d-b91a-1d9c425e7fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 33,600\n",
      " columns: 10\n",
      "\n",
      "columns:\n",
      "  1. child_id\n",
      "  2. timestamp\n",
      "  3. age\n",
      "  4. condition\n",
      "  5. heart_rate\n",
      "  6. activity_level\n",
      "  7. location\n",
      "  8. latitude\n",
      "  9. longitude\n",
      "  10. incident_type\n",
      "\n",
      "    child_id            timestamp  age condition  heart_rate  activity_level  \\\n",
      "0  child_000  2026-01-30 07:00:00   10    normal          78              15   \n",
      "1  child_000  2026-01-30 07:15:00   10    normal          80              29   \n",
      "2  child_000  2026-01-30 07:30:00   10    normal          78              28   \n",
      "3  child_000  2026-01-30 07:45:00   10    normal          75              25   \n",
      "4  child_000  2026-01-30 08:00:00   10    normal          82              28   \n",
      "\n",
      "    location   latitude  longitude incident_type  \n",
      "0  في الطريق  30.054326  31.245748          none  \n",
      "1  في الطريق  30.054471  31.245617          none  \n",
      "2  في الطريق  30.054315  31.245654          none  \n",
      "3  في الطريق  30.054439  31.245778          none  \n",
      "4    المدرسة  30.064449  31.255787          none  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Basic information about data\n",
    "\n",
    "print(f\"rows: {len(df):,}\")\n",
    "print(f\" columns: {len(df.columns)}\")\n",
    "print()\n",
    "\n",
    "print(\"columns:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "print()\n",
    "\n",
    "# أول 5 صفوف\n",
    "print(df.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddfb70f-b64e-48a5-a0ef-2f01814b3fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child_id           object\n",
      "timestamp          object\n",
      "age                 int64\n",
      "condition          object\n",
      "heart_rate          int64\n",
      "activity_level      int64\n",
      "location           object\n",
      "latitude          float64\n",
      "longitude         float64\n",
      "incident_type      object\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Data Types\n",
    "print(df.dtypes)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cd66be-9cbc-4504-a947-acff1688147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"No missing values\")\n",
    "else:\n",
    "    print(\"missing values\")\n",
    "    print(missing[missing > 0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5655b93-f34f-4693-a805-f4c255a59435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                age    heart_rate  activity_level      latitude     longitude\n",
      "count  33600.000000  33600.000000    33600.000000  33600.000000  33600.000000\n",
      "mean       8.760000     98.221935       52.468988     30.055233     31.246533\n",
      "std        2.209648     16.899822       24.464470      0.012556      0.012556\n",
      "min        5.000000     66.000000        0.000000     30.034300     31.225600\n",
      "25%        7.000000     88.000000       32.000000     30.049350     31.240650\n",
      "50%        9.000000     95.000000       50.000000     30.064329     31.255629\n",
      "75%       11.000000    102.000000       71.000000     30.064414     31.255715\n",
      "max       12.000000    191.000000      157.000000     30.064500     31.255800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d56baa0-203b-42d0-abf5-e01e4521cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child Distribution\n",
      "______________________________________________________________________\n",
      "Total children: 100\n",
      "\n",
      "By condition:\n",
      "condition\n",
      "adhd      22\n",
      "autism    26\n",
      "normal    52\n",
      "Name: child_id, dtype: int64\n",
      "\n",
      "By age:\n",
      "age\n",
      "5     3696\n",
      "6     4032\n",
      "7     2016\n",
      "8     4368\n",
      "9     4368\n",
      "10    6384\n",
      "11    5376\n",
      "12    3360\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Child distribution\n",
    "\n",
    "print(\"Child Distribution\")\n",
    "print(\"_\" * 70)\n",
    "\n",
    "print(f\"Total children: {df['child_id'].nunique()}\")\n",
    "print()\n",
    "print(\"By condition:\")\n",
    "print(df.groupby('condition')['child_id'].nunique())\n",
    "print()\n",
    "print(\"By age:\")\n",
    "print(df['age'].value_counts().sort_index())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f78c6e0-ae20-49d6-b40a-69573632d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident Distribution\n",
      "______________________________________________________________________\n",
      "incident_type\n",
      "none                31309\n",
      "potential_danger     1230\n",
      "anxiety_attack        600\n",
      "intense_exercise      347\n",
      "fall                  114\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total incidents: 2,291\n",
      "Incident rate: 6.82%\n",
      "\n",
      "Potential danger incidents: 1,230\n",
      "Percentage: 3.66%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Incident distribution\n",
    "\n",
    "print(\"Incident Distribution\")\n",
    "print(\"_\" * 70)\n",
    "incident_counts = df['incident_type'].value_counts()\n",
    "print(incident_counts)\n",
    "print()\n",
    "total_incidents = len(df[df['incident_type'] != 'none'])\n",
    "print(f\"Total incidents: {total_incidents:,}\")\n",
    "print(f\"Incident rate: {(total_incidents/len(df)*100):.2f}%\")\n",
    "print()\n",
    "\n",
    "if 'potential_danger' in incident_counts:\n",
    "    danger_count = incident_counts['potential_danger']\n",
    "    print(f\"Potential danger incidents: {danger_count:,}\")\n",
    "    print(f\"Percentage: {(danger_count/len(df)*100):.2f}%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3441c8-7e53-4b2a-80bb-77a4f0bc08b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summary report...\n",
      "Summary saved: data/data_summary.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save summary\n",
    "print(\"Saving summary report...\")\n",
    "summary = f\"\"\"\n",
    "Safe Kids Data Analysis - Summary Report\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Dataset Overview:\n",
    "- Total readings: {len(df):,}\n",
    "- Children: {df['child_id'].nunique()}\n",
    "- Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\n",
    "\n",
    "Condition Distribution:\n",
    "{df['condition'].value_counts()}\n",
    "\n",
    "Incident Distribution:\n",
    "{df['incident_type'].value_counts()}\n",
    "\n",
    "Heart Rate Statistics:\n",
    "- Mean: {df['heart_rate'].mean():.1f}\n",
    "- Std: {df['heart_rate'].std():.1f}\n",
    "- Min: {df['heart_rate'].min()}\n",
    "- Max: {df['heart_rate'].max()}\n",
    "\n",
    "Activity Level Statistics:\n",
    "- Mean: {df['activity_level'].mean():.1f}\n",
    "- Std: {df['activity_level'].std():.1f}\n",
    "- Min: {df['activity_level'].min()}\n",
    "- Max: {df['activity_level'].max()}\n",
    "\"\"\"\n",
    "\n",
    "with open('data/data_summary.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"Summary saved: data/data_summary.txt\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "485ccf54-d1e1-435d-bd4e-7ecd4d3db3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Generating Visualizations\n",
      "======================================================================\n",
      "\n",
      "Creating visualization 1: Heart rate distribution...\n",
      "Saved: visualizations/01_heart_rate_distribution.png\n",
      "Creating visualization 2: Activity distribution...\n",
      "Saved: visualizations/02_activity_distribution.png\n",
      "Creating visualization 3: Heart rate vs activity...\n",
      "Saved: visualizations/03_hr_vs_activity.png\n",
      "Creating visualization 4: Incident distribution...\n",
      "Saved: visualizations/04_incidents_distribution.png\n",
      "Creating visualization 5: Heart rate by time of day...\n",
      "Saved: visualizations/05_hr_by_time.png\n",
      "Creating visualization 6: Condition comparison...\n",
      "Saved: visualizations/06_conditions_comparison.png\n",
      "\n",
      "All visualizations created successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizations\n",
    "print(\"=\" * 70)\n",
    "print(\"Generating Visualizations\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "import os\n",
    "os.makedirs('visualizations', exist_ok=True)\n",
    "\n",
    "\n",
    "# Plot 1: Heart rate distribution\n",
    "print(\"Creating visualization 1: Heart rate distribution...\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['heart_rate'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(df['heart_rate'].mean(), color='red', linestyle='--', \n",
    "            label=f'Mean: {df[\"heart_rate\"].mean():.1f}')\n",
    "plt.xlabel('Heart Rate (BPM)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Heart Rate Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df.boxplot(column='heart_rate', by='condition', ax=plt.gca())\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Heart Rate (BPM)')\n",
    "plt.title('Heart Rate by Condition')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/01_heart_rate_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: visualizations/01_heart_rate_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot 2: Activity distribution\n",
    "print(\"Creating visualization 2: Activity distribution...\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['activity_level'], bins=50, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(df['activity_level'].mean(), color='red', linestyle='--',\n",
    "            label=f'Mean: {df[\"activity_level\"].mean():.1f}')\n",
    "plt.xlabel('Activity Level (0-100)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Activity Level Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df.boxplot(column='activity_level', by='condition', ax=plt.gca())\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Activity Level')\n",
    "plt.title('Activity by Condition')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/02_activity_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: visualizations/02_activity_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot 3: HR vs Activity scatter\n",
    "print(\"Creating visualization 3: Heart rate vs activity...\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "colors = {\n",
    "    'none': 'lightblue',\n",
    "    'potential_danger': 'red',\n",
    "    'anxiety_attack': 'orange',\n",
    "    'intense_exercise': 'green',\n",
    "    'fall': 'purple'\n",
    "}\n",
    "\n",
    "for incident_type, color in colors.items():\n",
    "    subset = df[df['incident_type'] == incident_type]\n",
    "    plt.scatter(subset['heart_rate'], subset['activity_level'], \n",
    "                c=color, label=incident_type, alpha=0.5, s=20)\n",
    "\n",
    "plt.xlabel('Heart Rate (BPM)')\n",
    "plt.ylabel('Activity Level (0-100)')\n",
    "plt.title('Heart Rate vs Activity Level by Incident Type')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig('visualizations/03_hr_vs_activity.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: visualizations/03_hr_vs_activity.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot 4: Incident distribution\n",
    "print(\"Creating visualization 4: Incident distribution...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "incident_counts = df['incident_type'].value_counts()\n",
    "colors_list = ['lightblue' if x == 'none' else 'red' if x == 'potential_danger' \n",
    "               else 'orange' if x == 'anxiety_attack' else 'green' if x == 'intense_exercise'\n",
    "               else 'purple' for x in incident_counts.index]\n",
    "\n",
    "plt.bar(incident_counts.index, incident_counts.values, color=colors_list, edgecolor='black')\n",
    "plt.xlabel('Incident Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Incident Type Distribution')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, (idx, val) in enumerate(incident_counts.items()):\n",
    "    plt.text(i, val, f'{val:,}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/04_incidents_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: visualizations/04_incidents_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot 5: Time series\n",
    "print(\"Creating visualization 5: Heart rate by time of day...\")\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "hourly_hr = df.groupby('hour')['heart_rate'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(hourly_hr.index, hourly_hr.values, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Heart Rate (BPM)')\n",
    "plt.title('Average Heart Rate by Time of Day')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(0, 24, 2))\n",
    "\n",
    "plt.axvspan(7, 8, alpha=0.2, color='yellow', label='Transit')\n",
    "plt.axvspan(8, 15, alpha=0.2, color='orange', label='School')\n",
    "plt.axvspan(15, 19, alpha=0.2, color='green', label='Play')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/05_hr_by_time.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: visualizations/05_hr_by_time.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot 6: Condition comparison\n",
    "print(\"Creating visualization 6: Condition comparison...\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, condition in enumerate(['normal', 'autism', 'adhd']):\n",
    "    condition_data = df[df['condition'] == condition]\n",
    "    axes[i].scatter(condition_data['heart_rate'], condition_data['activity_level'], \n",
    "                    alpha=0.3, s=10)\n",
    "    axes[i].set_title(f'{condition.upper()}')\n",
    "    axes[i].set_xlabel('Heart Rate')\n",
    "    axes[i].set_ylabel('Activity Level')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/06_conditions_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: visualizations/06_conditions_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "print()\n",
    "print(\"All visualizations created successfully\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bcef5a1-0a42-4729-a330-86d1b3f0acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern Analysis\n",
      "______________________________________________________________________\n",
      "\n",
      "Comparison: Normal vs Potential Danger\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Normal readings (31,309):\n",
      "  Heart rate:\n",
      "    Mean: 94.4\n",
      "    Std: 8.6\n",
      "    Range: 66 - 123\n",
      "  Activity level:\n",
      "    Mean: 49.7\n",
      "    Std: 21.5\n",
      "\n",
      "Potential danger (1,230):\n",
      "  Heart rate:\n",
      "    Mean: 159.9\n",
      "    Std: 10.8\n",
      "    Range: 128 - 191\n",
      "  Activity level:\n",
      "    Mean: 99.1\n",
      "    Std: 22.7\n",
      "\n",
      "Difference:\n",
      "  Heart rate: +65.5 BPM in danger situations\n",
      "  Activity level: +49.4 in danger situations\n",
      "\n",
      "Location Analysis\n",
      "______________________________________________________________________\n",
      "\n",
      "Incidents by location:\n",
      "  المدرسة: 1,300 incidents (56.7%)\n",
      "  النادي: 607 incidents (26.5%)\n",
      "  في الطريق: 384 incidents (16.8%)\n",
      "\n",
      "Condition Analysis\n",
      "______________________________________________________________________\n",
      "\n",
      "NORMAL:\n",
      "  Children: 52\n",
      "  Total readings: 17,472\n",
      "  Incidents: 1,206\n",
      "  Incident rate: 6.90%\n",
      "  Mean heart rate: 96.5\n",
      "  Mean activity: 48.7\n",
      "\n",
      "AUTISM:\n",
      "  Children: 26\n",
      "  Total readings: 8,736\n",
      "  Incidents: 590\n",
      "  Incident rate: 6.75%\n",
      "  Mean heart rate: 99.3\n",
      "  Mean activity: 48.4\n",
      "\n",
      "ADHD:\n",
      "  Children: 22\n",
      "  Total readings: 7,392\n",
      "  Incidents: 495\n",
      "  Incident rate: 6.70%\n",
      "  Mean heart rate: 101.1\n",
      "  Mean activity: 66.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pattern analysis\n",
    "\n",
    "print(\"Pattern Analysis\")\n",
    "print(\"_\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"Comparison: Normal vs Potential Danger\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "normal_readings = df[df['incident_type'] == 'none']\n",
    "danger_readings = df[df['incident_type'] == 'potential_danger']\n",
    "\n",
    "print(f\"\\nNormal readings ({len(normal_readings):,}):\")\n",
    "print(f\"  Heart rate:\")\n",
    "print(f\"    Mean: {normal_readings['heart_rate'].mean():.1f}\")\n",
    "print(f\"    Std: {normal_readings['heart_rate'].std():.1f}\")\n",
    "print(f\"    Range: {normal_readings['heart_rate'].min()} - {normal_readings['heart_rate'].max()}\")\n",
    "print(f\"  Activity level:\")\n",
    "print(f\"    Mean: {normal_readings['activity_level'].mean():.1f}\")\n",
    "print(f\"    Std: {normal_readings['activity_level'].std():.1f}\")\n",
    "\n",
    "print(f\"\\nPotential danger ({len(danger_readings):,}):\")\n",
    "print(f\"  Heart rate:\")\n",
    "print(f\"    Mean: {danger_readings['heart_rate'].mean():.1f}\")\n",
    "print(f\"    Std: {danger_readings['heart_rate'].std():.1f}\")\n",
    "print(f\"    Range: {danger_readings['heart_rate'].min()} - {danger_readings['heart_rate'].max()}\")\n",
    "print(f\"  Activity level:\")\n",
    "print(f\"    Mean: {danger_readings['activity_level'].mean():.1f}\")\n",
    "print(f\"    Std: {danger_readings['activity_level'].std():.1f}\")\n",
    "\n",
    "hr_diff = danger_readings['heart_rate'].mean() - normal_readings['heart_rate'].mean()\n",
    "activity_diff = danger_readings['activity_level'].mean() - normal_readings['activity_level'].mean()\n",
    "\n",
    "print(f\"\\nDifference:\")\n",
    "print(f\"  Heart rate: +{hr_diff:.1f} BPM in danger situations\")\n",
    "print(f\"  Activity level: +{activity_diff:.1f} in danger situations\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Location analysis\n",
    "\n",
    "print(\"Location Analysis\")\n",
    "print(\"_\" * 70)\n",
    "\n",
    "location_incidents = df[df['incident_type'] != 'none'].groupby('location').size().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nIncidents by location:\")\n",
    "for location, count in location_incidents.items():\n",
    "    percentage = (count / len(df[df['incident_type'] != 'none'])) * 100\n",
    "    print(f\"  {location}: {count:,} incidents ({percentage:.1f}%)\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Condition analysis\n",
    "\n",
    "print(\"Condition Analysis\")\n",
    "print(\"_\" * 70)\n",
    "\n",
    "for condition in ['normal', 'autism', 'adhd']:\n",
    "    condition_data = df[df['condition'] == condition]\n",
    "    condition_incidents = condition_data[condition_data['incident_type'] != 'none']\n",
    "    \n",
    "    print(f\"\\n{condition.upper()}:\")\n",
    "    print(f\"  Children: {condition_data['child_id'].nunique()}\")\n",
    "    print(f\"  Total readings: {len(condition_data):,}\")\n",
    "    print(f\"  Incidents: {len(condition_incidents):,}\")\n",
    "    print(f\"  Incident rate: {(len(condition_incidents)/len(condition_data)*100):.2f}%\")\n",
    "    print(f\"  Mean heart rate: {condition_data['heart_rate'].mean():.1f}\")\n",
    "    print(f\"  Mean activity: {condition_data['activity_level'].mean():.1f}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a3743f5-3ff6-49f3-8cd7-85c9664c60aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Feature Engineering\n",
      "======================================================================\n",
      "\n",
      "Adding features:\n",
      "  1. is_high_hr (heart rate > 110)\n",
      "  2. is_high_activity (activity > 60)\n",
      "  3. hr_to_activity_ratio\n",
      "  4. is_school_time (8 AM - 3 PM)\n",
      "  5. in_safe_zone\n",
      "  6. is_dangerous (label for ML)\n",
      "Saving enhanced dataset...\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering\n",
    "print(\"=\" * 70)\n",
    "print(\"Feature Engineering\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "df_enhanced = df.copy()\n",
    "\n",
    "df_enhanced['timestamp'] = pd.to_datetime(df_enhanced['timestamp'])\n",
    "df_enhanced['hour'] = df_enhanced['timestamp'].dt.hour\n",
    "\n",
    "df_enhanced['is_school_time'] = df_enhanced['hour'].apply(\n",
    "    lambda x: 1 if 8 <= x < 15 else 0\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Adding features:\")\n",
    "print(\"  1. is_high_hr (heart rate > 110)\")\n",
    "df_enhanced['is_high_hr'] = (df_enhanced['heart_rate'] > 110).astype(int)\n",
    "\n",
    "print(\"  2. is_high_activity (activity > 60)\")\n",
    "df_enhanced['is_high_activity'] = (df_enhanced['activity_level'] > 60).astype(int)\n",
    "\n",
    "print(\"  3. hr_to_activity_ratio\")\n",
    "df_enhanced['hr_to_activity_ratio'] = df_enhanced['heart_rate'] / (df_enhanced['activity_level'] + 1)\n",
    "\n",
    "print(\"  4. is_school_time (8 AM - 3 PM)\")\n",
    "df_enhanced['is_school_time'] = df_enhanced['hour'].apply(lambda x: 1 if 8 <= x < 15 else 0)\n",
    "\n",
    "print(\"  5. in_safe_zone\")\n",
    "safe_locations = ['home', 'school']\n",
    "df_enhanced['in_safe_zone'] = df_enhanced['location'].apply(lambda x: 1 if x in safe_locations else 0)\n",
    "\n",
    "print(\"  6. is_dangerous (label for ML)\")\n",
    "df_enhanced['is_dangerous'] = (df_enhanced['incident_type'] != 'none').astype(int)\n",
    "\n",
    "\n",
    "print(\"Saving enhanced dataset...\")\n",
    "df_enhanced.to_csv('data/enhanced_data.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa733c42-0829-401c-b576-56cc62135631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anomaly Detection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfa2e31e-c983-4e53-b6f1-1acd38492dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: Z-Score\n",
      "Detected anomalies: 1,721\n",
      "Percentage: 5.12%\n",
      "\n",
      "____________________________________________________________\n",
      "Method 2: IQR\n",
      "Normal range: 67.0 - 123.0\n",
      "Detected anomalies: 2,061\n",
      "Percentage: 6.13%\n",
      "\n",
      "____________________________________________________________\n",
      "Method 3: Isolation Forest (Machine Learning)\n",
      "Detected anomalies: 2,351\n",
      "Percentage: 7.00%\n",
      "\n",
      "____________________________________________________________\n",
      "Comparison of the Three Methods\n",
      "____________________________________________________________\n",
      "\n",
      "Actual incidents (Ground Truth): 2,291\n",
      "\n",
      "Z-Score:\n",
      "  Detected: 1,721 cases\n",
      "  True Positive: 1,721\n",
      "  False Positive: 0\n",
      "  Precision: 100.00%\n",
      "  Recall: 75.12%\n",
      "\n",
      "IQR:\n",
      "  Detected: 2,061 cases\n",
      "  True Positive: 2,060\n",
      "  False Positive: 1\n",
      "  Precision: 99.95%\n",
      "  Recall: 89.92%\n",
      "\n",
      "ML (Isolation Forest):\n",
      "  Detected: 2,351 cases\n",
      "  True Positive: 1,773\n",
      "  False Positive: 578\n",
      "  Precision: 75.41%\n",
      "  Recall: 77.39%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/enhanced_data.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Method 1: Z-Score\n",
    "print(\"Method 1: Z-Score\")\n",
    "\n",
    "def detect_anomaly_zscore(df, column='heart_rate', threshold=2.5):\n",
    "\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    \n",
    "    # Calculate Z-Score\n",
    "    df['z_score'] = np.abs((df[column] - mean) / std)\n",
    "    \n",
    "    # Mark anomaly\n",
    "    df['is_anomaly_zscore'] = (df['z_score'] > threshold).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = detect_anomaly_zscore(df, column='heart_rate', threshold=2.5)\n",
    "\n",
    "anomalies_zscore = df[df['is_anomaly_zscore'] == 1]\n",
    "print(f\"Detected anomalies: {len(anomalies_zscore):,}\")\n",
    "print(f\"Percentage: {(len(anomalies_zscore)/len(df)*100):.2f}%\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Method 2: IQR\n",
    "\n",
    "print(\"_\" * 60)\n",
    "print(\"Method 2: IQR\")\n",
    "\n",
    "\n",
    "def detect_anomaly_iqr(df, column='heart_rate'):\n",
    "    \"\"\"\n",
    "    Detect anomaly using IQR\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    print(f\"Normal range: {lower_bound:.1f} - {upper_bound:.1f}\")\n",
    "    \n",
    "    # Mark anomaly\n",
    "    df['is_anomaly_iqr'] = (\n",
    "        (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply\n",
    "df = detect_anomaly_iqr(df, column='heart_rate')\n",
    "\n",
    "anomalies_iqr = df[df['is_anomaly_iqr'] == 1]\n",
    "print(f\"Detected anomalies: {len(anomalies_iqr):,}\")\n",
    "print(f\"Percentage: {(len(anomalies_iqr)/len(df)*100):.2f}%\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Method 3: Isolation Forest (ML)\n",
    "\n",
    "print(\"_\" * 60)\n",
    "print(\"Method 3: Isolation Forest (Machine Learning)\")\n",
    "\n",
    "\n",
    "# Prepare data for ML\n",
    "features = ['heart_rate', 'activity_level', 'hr_to_activity_ratio']\n",
    "X = df[features].values\n",
    "\n",
    "# Train model\n",
    "\n",
    "model = IsolationForest(\n",
    "    contamination=0.07,  # Expected anomaly rate (7%)\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X)\n",
    "\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(X)\n",
    "df['is_anomaly_ml'] = (predictions == -1).astype(int)  # -1 = anomaly\n",
    "\n",
    "anomalies_ml = df[df['is_anomaly_ml'] == 1]\n",
    "print(f\"Detected anomalies: {len(anomalies_ml):,}\")\n",
    "print(f\"Percentage: {(len(anomalies_ml)/len(df)*100):.2f}%\")\n",
    "print()\n",
    "\n",
    "# Compare the three methods\n",
    "\n",
    "print(\"_\" * 60)\n",
    "print(\"Comparison of the Three Methods\")\n",
    "print(\"_\" * 60)\n",
    "print()\n",
    "\n",
    "# Ground truth (from data)\n",
    "actual_anomalies = df[df['incident_type'] != 'none']\n",
    "\n",
    "print(f\"Actual incidents (Ground Truth): {len(actual_anomalies):,}\")\n",
    "print()\n",
    "\n",
    "# Comparison\n",
    "methods = {\n",
    "    'Z-Score': 'is_anomaly_zscore',\n",
    "    'IQR': 'is_anomaly_iqr',\n",
    "    'ML (Isolation Forest)': 'is_anomaly_ml'\n",
    "}\n",
    "\n",
    "for method_name, column in methods.items():\n",
    "    detected = df[df[column] == 1]\n",
    "    \n",
    "    # How many actual incidents were detected?\n",
    "    true_positives = len(df[(df[column] == 1) & (df['incident_type'] != 'none')])\n",
    "    false_positives = len(df[(df[column] == 1) & (df['incident_type'] == 'none')])\n",
    "    \n",
    "    precision = true_positives / len(detected) if len(detected) > 0 else 0\n",
    "    recall = true_positives / len(actual_anomalies) if len(actual_anomalies) > 0 else 0\n",
    "    \n",
    "    print(f\"{method_name}:\")\n",
    "    print(f\"  Detected: {len(detected):,} cases\")\n",
    "    print(f\"  True Positive: {true_positives:,}\")\n",
    "    print(f\"  False Positive: {false_positives:,}\")\n",
    "    print(f\"  Precision: {precision:.2%}\")\n",
    "    print(f\"  Recall: {recall:.2%}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "df.to_csv('data/data_with_anomalies.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54e6d597-c8bf-4de4-b33f-8dbbb320dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Visualization\n",
    "\n",
    "os.makedirs('visualizations', exist_ok=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Z-Score Plot\n",
    "axes[0, 0].scatter(df[df['is_anomaly_zscore']==0]['heart_rate'],\n",
    "                   df[df['is_anomaly_zscore']==0]['activity_level'],\n",
    "                   alpha=0.3, s=10, label='Normal')\n",
    "axes[0, 0].scatter(df[df['is_anomaly_zscore']==1]['heart_rate'],\n",
    "                   df[df['is_anomaly_zscore']==1]['activity_level'],\n",
    "                   alpha=0.7, s=20, label='Anomaly')\n",
    "axes[0, 0].set_title('Z-Score Method')\n",
    "axes[0, 0].set_xlabel('Heart Rate')\n",
    "axes[0, 0].set_ylabel('Activity Level')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# IQR Plot\n",
    "axes[0, 1].scatter(df[df['is_anomaly_iqr']==0]['heart_rate'],\n",
    "                   df[df['is_anomaly_iqr']==0]['activity_level'],\n",
    "                   alpha=0.3, s=10, label='Normal')\n",
    "axes[0, 1].scatter(df[df['is_anomaly_iqr']==1]['heart_rate'],\n",
    "                   df[df['is_anomaly_iqr']==1]['activity_level'],\n",
    "                   alpha=0.7, s=20, label='Anomaly')\n",
    "axes[0, 1].set_title('IQR Method')\n",
    "axes[0, 1].set_xlabel('Heart Rate')\n",
    "axes[0, 1].set_ylabel('Activity Level')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Isolation Forest Plot\n",
    "axes[1, 0].scatter(df[df['is_anomaly_ml']==0]['heart_rate'],\n",
    "                   df[df['is_anomaly_ml']==0]['activity_level'],\n",
    "                   alpha=0.3, s=10, label='Normal')\n",
    "axes[1, 0].scatter(df[df['is_anomaly_ml']==1]['heart_rate'],\n",
    "                   df[df['is_anomaly_ml']==1]['activity_level'],\n",
    "                   alpha=0.7, s=20, label='Anomaly')\n",
    "axes[1, 0].set_title('Isolation Forest')\n",
    "axes[1, 0].set_xlabel('Heart Rate')\n",
    "axes[1, 0].set_ylabel('Activity Level')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Ground Truth Plot\n",
    "axes[1, 1].scatter(df[df['incident_type']=='none']['heart_rate'],\n",
    "                   df[df['incident_type']=='none']['activity_level'],\n",
    "                   alpha=0.3, s=10, label='Normal')\n",
    "axes[1, 1].scatter(df[df['incident_type']!='none']['heart_rate'],\n",
    "                   df[df['incident_type']!='none']['activity_level'],\n",
    "                   alpha=0.7, s=20, label='Incident')\n",
    "axes[1, 1].set_title('Ground Truth')\n",
    "axes[1, 1].set_xlabel('Heart Rate')\n",
    "axes[1, 1].set_ylabel('Activity Level')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/07_anomaly_detection_comparison.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885bd1dd-6102-4941-827d-2794a6b448a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/enhanced_data.csv\")\n",
    "\n",
    "features = [\n",
    "    'heart_rate',\n",
    "    'activity_level',\n",
    "    'is_high_hr',\n",
    "    'is_high_activity',\n",
    "    'hr_to_activity_ratio',\n",
    "    'is_school_time',\n",
    "    'in_safe_zone'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['is_dangerous']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6325fd-5f27-4c3a-887a-9799062306e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8346c8bb-333f-420c-9636-965f971ed7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9958\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6254    8]\n",
      " [  20  438]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6262\n",
      "           1       0.98      0.96      0.97       458\n",
      "\n",
      "    accuracy                           1.00      6720\n",
      "   macro avg       0.99      0.98      0.98      6720\n",
      "weighted avg       1.00      1.00      1.00      6720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27fe054e-9e85-48fb-ad3a-4fc69257b147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9915\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6225   37]\n",
      " [  20  438]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      6262\n",
      "           1       0.92      0.96      0.94       458\n",
      "\n",
      "    accuracy                           0.99      6720\n",
      "   macro avg       0.96      0.98      0.97      6720\n",
      "weighted avg       0.99      0.99      0.99      6720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5777cd-b06c-4a4f-a098-d33fdb14ffb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.5",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
